{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR1HCdj5AFtd",
        "colab_type": "code",
        "outputId": "4cf0fa0e-fa04-4aa3-c312-c43105c04fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Ge1rYCARAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Project')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnRNfJYa8eoN",
        "colab_type": "code",
        "outputId": "aed0680c-422c-47a5-be6b-037d8ba99f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QMpooU4LRks",
        "colab_type": "code",
        "outputId": "c5a935a0-1ffc-479f-e9dd-802eeb8aa984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbiyZlIFMUW8",
        "colab_type": "code",
        "outputId": "fdde560c-8dc0-4fc7-af39-6cdf0144c8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5pVEixQLgBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UuAxYMZL6nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD3LIveuMOvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYq9zxTNHA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "67c96f8d-c6ae-448a-f6bd-862d3fd3d7b1"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(16, (5,5), activation = \"relu\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0717 16:46:52.001409 140650791675776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0717 16:46:52.045342 140650791675776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0717 16:46:52.053856 140650791675776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0717 16:46:52.102512 140650791675776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaqY9aN18H7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b7679c3f-e52a-44ce-8672-77057fdbc51a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 9, 16)          12816     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
            "=================================================================\n",
            "Total params: 13,136\n",
            "Trainable params: 13,136\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kd_zJ7TUAMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rotation_range = 20,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   horizontal_flip = False, vertical_flip=False)\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "training_set = train_datagen.flow(train_images, train_labels,\n",
        "                                                 batch_size = 32)\n",
        "\n",
        "test_set = test_datagen.flow(test_images, test_labels, batch_size = 32)\n",
        "                                            \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzkCjOUL7C_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8BBWl8fYd9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cf765884-49d4-44bd-c74a-c2419e33f790"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0717 16:47:21.343842 140650791675776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0717 16:47:21.376572 140650791675776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OUbJj-pYIBN",
        "colab_type": "code",
        "outputId": "ab280d4d-7ff0-4340-a588-a38a72157241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(training_set,\n",
        "                         steps_per_epoch = 200,\n",
        "                         epochs = 75,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 200)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0717 16:47:30.110819 140650791675776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0717 16:47:30.205588 140650791675776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.8999 - acc: 0.7189 - val_loss: 0.2771 - val_acc: 0.9163\n",
            "Epoch 2/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.3823 - acc: 0.8853 - val_loss: 0.1659 - val_acc: 0.9530\n",
            "Epoch 3/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.2696 - acc: 0.9178 - val_loss: 0.1277 - val_acc: 0.9617\n",
            "Epoch 4/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.2228 - acc: 0.9331 - val_loss: 0.1104 - val_acc: 0.9659\n",
            "Epoch 5/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.1838 - acc: 0.9402 - val_loss: 0.0958 - val_acc: 0.9696\n",
            "Epoch 6/75\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.1672 - acc: 0.9467 - val_loss: 0.0842 - val_acc: 0.9719\n",
            "Epoch 7/75\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.1485 - acc: 0.9544 - val_loss: 0.0725 - val_acc: 0.9767\n",
            "Epoch 8/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.1413 - acc: 0.9556 - val_loss: 0.0705 - val_acc: 0.9771\n",
            "Epoch 9/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.1176 - acc: 0.9637 - val_loss: 0.0617 - val_acc: 0.9800\n",
            "Epoch 10/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.1257 - acc: 0.9597 - val_loss: 0.0778 - val_acc: 0.9759\n",
            "Epoch 11/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.1136 - acc: 0.9645 - val_loss: 0.0545 - val_acc: 0.9828\n",
            "Epoch 12/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.1065 - acc: 0.9672 - val_loss: 0.0524 - val_acc: 0.9834\n",
            "Epoch 13/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.1019 - acc: 0.9681 - val_loss: 0.0536 - val_acc: 0.9834\n",
            "Epoch 14/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0976 - acc: 0.9697 - val_loss: 0.0499 - val_acc: 0.9858\n",
            "Epoch 15/75\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0869 - acc: 0.9738 - val_loss: 0.0403 - val_acc: 0.9881\n",
            "Epoch 16/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0900 - acc: 0.9714 - val_loss: 0.0479 - val_acc: 0.9834\n",
            "Epoch 17/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0995 - acc: 0.9703 - val_loss: 0.0466 - val_acc: 0.9856\n",
            "Epoch 18/75\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0845 - acc: 0.9759 - val_loss: 0.0767 - val_acc: 0.9754\n",
            "Epoch 19/75\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0934 - acc: 0.9720 - val_loss: 0.0400 - val_acc: 0.9864\n",
            "Epoch 20/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0884 - acc: 0.9742 - val_loss: 0.0437 - val_acc: 0.9852\n",
            "Epoch 21/75\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0703 - acc: 0.9791 - val_loss: 0.0498 - val_acc: 0.9846\n",
            "Epoch 22/75\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0719 - acc: 0.9773 - val_loss: 0.0414 - val_acc: 0.9872\n",
            "Epoch 23/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0738 - acc: 0.9758 - val_loss: 0.0432 - val_acc: 0.9861\n",
            "Epoch 24/75\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0795 - acc: 0.9742 - val_loss: 0.0383 - val_acc: 0.9857\n",
            "Epoch 25/75\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0690 - acc: 0.9792 - val_loss: 0.0447 - val_acc: 0.9869\n",
            "Epoch 26/75\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0701 - acc: 0.9791 - val_loss: 0.0406 - val_acc: 0.9873\n",
            "Epoch 27/75\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0740 - acc: 0.9766 - val_loss: 0.0387 - val_acc: 0.9878\n",
            "Epoch 28/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.0363 - val_acc: 0.9872\n",
            "Epoch 29/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0719 - acc: 0.9783 - val_loss: 0.0362 - val_acc: 0.9879\n",
            "Epoch 30/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0609 - acc: 0.9794 - val_loss: 0.0365 - val_acc: 0.9872\n",
            "Epoch 31/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0722 - acc: 0.9781 - val_loss: 0.0357 - val_acc: 0.9881\n",
            "Epoch 32/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0655 - acc: 0.9792 - val_loss: 0.0269 - val_acc: 0.9925\n",
            "Epoch 33/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0526 - acc: 0.9834 - val_loss: 0.0366 - val_acc: 0.9873\n",
            "Epoch 34/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0552 - acc: 0.9834 - val_loss: 0.0541 - val_acc: 0.9845\n",
            "Epoch 35/75\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.0714 - acc: 0.9783 - val_loss: 0.0306 - val_acc: 0.9904\n",
            "Epoch 36/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0626 - acc: 0.9825 - val_loss: 0.0401 - val_acc: 0.9884\n",
            "Epoch 37/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0544 - acc: 0.9836 - val_loss: 0.0316 - val_acc: 0.9884\n",
            "Epoch 38/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0711 - acc: 0.9789 - val_loss: 0.0353 - val_acc: 0.9887\n",
            "Epoch 39/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0605 - acc: 0.9819 - val_loss: 0.0351 - val_acc: 0.9894\n",
            "Epoch 40/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0672 - acc: 0.9806 - val_loss: 0.0358 - val_acc: 0.9898\n",
            "Epoch 41/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0531 - acc: 0.9836 - val_loss: 0.0474 - val_acc: 0.9872\n",
            "Epoch 42/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0443 - acc: 0.9864 - val_loss: 0.0414 - val_acc: 0.9886\n",
            "Epoch 43/75\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.0636 - acc: 0.9808 - val_loss: 0.0265 - val_acc: 0.9925\n",
            "Epoch 44/75\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.0620 - acc: 0.9822 - val_loss: 0.0463 - val_acc: 0.9850\n",
            "Epoch 45/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0583 - acc: 0.9808 - val_loss: 0.0343 - val_acc: 0.9888\n",
            "Epoch 46/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0629 - acc: 0.9806 - val_loss: 0.0336 - val_acc: 0.9897\n",
            "Epoch 47/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0529 - acc: 0.9847 - val_loss: 0.0288 - val_acc: 0.9912\n",
            "Epoch 48/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0590 - acc: 0.9837 - val_loss: 0.0443 - val_acc: 0.9862\n",
            "Epoch 49/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0551 - acc: 0.9817 - val_loss: 0.0333 - val_acc: 0.9904\n",
            "Epoch 50/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0433 - acc: 0.9856 - val_loss: 0.0367 - val_acc: 0.9880\n",
            "Epoch 51/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0560 - acc: 0.9836 - val_loss: 0.0309 - val_acc: 0.9909\n",
            "Epoch 52/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0583 - acc: 0.9830 - val_loss: 0.0433 - val_acc: 0.9879\n",
            "Epoch 53/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0612 - acc: 0.9830 - val_loss: 0.0298 - val_acc: 0.9898\n",
            "Epoch 54/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0503 - acc: 0.9825 - val_loss: 0.0383 - val_acc: 0.9890\n",
            "Epoch 55/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0602 - acc: 0.9828 - val_loss: 0.0319 - val_acc: 0.9900\n",
            "Epoch 56/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0498 - acc: 0.9856 - val_loss: 0.0360 - val_acc: 0.9892\n",
            "Epoch 57/75\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0479 - acc: 0.9839 - val_loss: 0.0301 - val_acc: 0.9911\n",
            "Epoch 58/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0500 - acc: 0.9836 - val_loss: 0.0315 - val_acc: 0.9898\n",
            "Epoch 59/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0542 - acc: 0.9847 - val_loss: 0.0410 - val_acc: 0.9880\n",
            "Epoch 60/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0596 - acc: 0.9850 - val_loss: 0.0290 - val_acc: 0.9914\n",
            "Epoch 61/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0525 - acc: 0.9837 - val_loss: 0.0319 - val_acc: 0.9906\n",
            "Epoch 62/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0418 - acc: 0.9861 - val_loss: 0.0373 - val_acc: 0.9908\n",
            "Epoch 63/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0516 - acc: 0.9864 - val_loss: 0.0294 - val_acc: 0.9920\n",
            "Epoch 64/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0538 - acc: 0.9852 - val_loss: 0.0355 - val_acc: 0.9906\n",
            "Epoch 65/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0479 - acc: 0.9848 - val_loss: 0.0608 - val_acc: 0.9851\n",
            "Epoch 66/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0489 - acc: 0.9848 - val_loss: 0.0290 - val_acc: 0.9911\n",
            "Epoch 67/75\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.0494 - acc: 0.9850 - val_loss: 0.0297 - val_acc: 0.9903\n",
            "Epoch 68/75\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.0442 - acc: 0.9869 - val_loss: 0.0366 - val_acc: 0.9909\n",
            "Epoch 69/75\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.0545 - acc: 0.9830 - val_loss: 0.0323 - val_acc: 0.9897\n",
            "Epoch 70/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0476 - acc: 0.9859 - val_loss: 0.0333 - val_acc: 0.9903\n",
            "Epoch 71/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0535 - acc: 0.9833 - val_loss: 0.0341 - val_acc: 0.9904\n",
            "Epoch 72/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0553 - acc: 0.9833 - val_loss: 0.0278 - val_acc: 0.9920\n",
            "Epoch 73/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0473 - acc: 0.9853 - val_loss: 0.0350 - val_acc: 0.9902\n",
            "Epoch 74/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0483 - acc: 0.9842 - val_loss: 0.0336 - val_acc: 0.9914\n",
            "Epoch 75/75\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0495 - acc: 0.9855 - val_loss: 0.0264 - val_acc: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feb96c5c748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVgzppjszaov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}